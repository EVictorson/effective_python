{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Concurrency and Parallelism\n",
    "\n",
    "**Concurrency** enables a computer to do many different things **seemingly** at the same time.  For example, on a computer with one CPU core, the operating system rapidly changes which program is running on the single processor.  In doing so, it interleaves execution of the programs providing the illusion that hte programs are running simultaneously.  \n",
    "\n",
    "**Parallelism**, in contrast, involves **actually** doing many different things at the same time.  A computer with multiple CPU cores can execute multiple programs simultaneously.  Each CPU core runs the instructions of a seperate program, allowing each program to make forward progress during the same instant.  \n",
    "\n",
    "Within a single program, concurrency is a tool that makes it easier for programmers to solve certain types of problems.  \n",
    "\n",
    "The key difference between parallelism and concurrency is **speedup**.  When two distinct paths of execution in a program make forward progress in parallel, the time it takes to do the total work is cut in half.  \n",
    "\n",
    "Threads support a relatively small amount of concurrency, while coroutines enable vast numbers of concurrent functions.  It can be very difficult to make concurrent Python code truly run in parallel.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 52: Use `subprocess` to Manage Child Processes\n",
    "\n",
    "Python has pretty robust libraries for runing and managing child processes.  This makes it a great language for gluing together other tools, such as command-line utilities.  When existing shell scripts get complicated, as they often do over time, graduating them to a rewrite in Python for the sake of readability and maintainability is a natural choice.  \n",
    "\n",
    "Child processes start by Python are able to run in parallel, enabling you to use Python to consume all of the CPU cores of a machine and maximize the throughput of programs.  Although Python itself may be CPU bound, it's easy to use Python to drive and coordinate CPU-intensive workloads.  \n",
    "\n",
    "The best option for managing child processes is to use the `subprocess` built-in module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from the child!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['echo', 'Hello from the child!'],\n",
    "    capture_output=True,\n",
    "    encoding='utf-8')\n",
    "\n",
    "result.check_returncode()  # No exception means it exited cleanly\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Child processes run independently from their parent processes, the Python interpreter.  If I create a subprocess using the `Popen` class instead of the run function, I can poll the child process status periodically while Python does other work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Exit status 0\n"
     ]
    }
   ],
   "source": [
    "proc = subprocess.Popen(['sleep', '1'])\n",
    "while proc.poll() is None:\n",
    "    print('Working...')\n",
    "    # Some time-consuming work here\n",
    "    import time\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print('Exit status', proc.poll())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoupling the child process fro mthe parent frees up the parent process to run many child processes in parallel.  Here, I do this by starting all the child processes together with `Popen` upfront:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 1.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sleep_procs = []\n",
    "for _ in range(10):\n",
    "    # Use this line instead to make this example work on Windows\n",
    "    # proc = subprocess.Popen(['sleep', '1'], shell=True)\n",
    "    proc = subprocess.Popen(['sleep', '1'])\n",
    "    sleep_procs.append(proc)\n",
    "    \n",
    "for proc in sleep_procs:\n",
    "    proc.communicate()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Finished in {delta:.3} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pipe data from a Python program into a subprocess and retrive its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x19P\\x90\\xd7\\xba\\xc9\\x1f\\x96^;'\n",
      "b'\\xdc\\xac\\xae\\x02\\x19sz\\xf9\\xa4\\x16'\n",
      "b's}\\xcdA\\xd6\\x9aF\\x90U\\x9f'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# On Windows, after installing OpenSSL, you may need to\n",
    "# alias it in your PowerShell path with a command like:\n",
    "# $env:path = $env:path + \";C:\\Program Files\\OpenSSL-Win64\\bin\"\n",
    "\n",
    "def run_encrypt(data):\n",
    "    env = os.environ.copy()\n",
    "    env['password'] = 'zf7ShyBhZOraQDdE/FiZpm/m/8f9X+M1'\n",
    "    proc = subprocess.Popen(\n",
    "        ['openssl', 'enc', '-des3', '-pass', 'env:password'],\n",
    "        env=env,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE)\n",
    "    proc.stdin.write(data)\n",
    "    proc.stdin.flush()  # Ensure that the child gets input\n",
    "    return proc\n",
    "\n",
    "\n",
    "# Example 6\n",
    "procs = []\n",
    "for _ in range(3):\n",
    "    data = os.urandom(10)\n",
    "    proc = run_encrypt(data)\n",
    "    procs.append(proc)\n",
    "    \n",
    "for proc in procs:\n",
    "    out, _ = proc.communicate()\n",
    "    print(out[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the subprocess module to run child processes and manage their input and output streams.  \n",
    "\n",
    "Child processes run in parallel with the Python interpreter, enabling you to maximize your usage of CPU cores.  \n",
    "\n",
    "Use the `run` convenience function for simple usage, and the `Popen` class for advanced usage line UNIX-style pipelines.  \n",
    "\n",
    "Use the `timeout` parameter of the `communicate` method to avoid deadlocks and hanging child processes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 53: Use Threads for Blocking I/O, Avoid for Parallelism  \n",
    "\n",
    "The standard implementation of Python is called CPython.  CPython runs a Python program in two steps:\n",
    "1. it parses and compiles the source text into **bytecode**, which is a low-level representation of the program as 8-bit instructions.  As of Python 3.6 this is actually 16-bit **wordcode**.\n",
    "2. CPython then runs the bytecode using a stack-based interpreter.  The bytecode interpreter has state that must be maintained and coherent while the Python program executes.  CPython enforces coherence with a mechanism called the **global interpreter lock (GIL)**.  \n",
    "\n",
    "Essentially, the GIL is a mutual exclusion lock (mutex) that prevents CPython from being affected by preemptive multithreading, where one thread takes control of a program by interrupting another thread.  Such an interruption could corrupt the interpreter state (e.g. garbage collection reference counts) if it comes at an unexpected time.  The GIL prevents these interruptions and ensures that every bytecode instruction works correctly with the CPython implementation and its C-extension modules.  \n",
    "\n",
    "The downside of the GIL is that, opposed to languages like C++ or Java where having multiple threads of execution means that a program could utilize multiple CPU cores at the same time, Python doesn't allow for this.  The GIL only allows one execution thread to progress at a time.  This means that if you reach for threads to do parallel computation and speed up your Python programs, you will be disappointed.\n",
    "\n",
    "Despite these perhaps perceived shortcomings, Python supports threads for two good reasons:\n",
    "1. Multiple threads make it easy for a program to seem like it's doing multiple things at the same time, as opposed to you having to juggle things.\n",
    "2. To deal with blocking I/O.\n",
    "\n",
    "Blocking I/O includes things like reading and writing files, interacting with networks, communicating with devices like displays, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "import select\n",
    "import socket\n",
    "from threading import Thread\n",
    "\n",
    "def slow_systemcall():\n",
    "    select.select([socket.socket()], [], [], 0.1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(5):\n",
    "    slow_systemcall()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Took {delta:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you find yourself needing to do blocking I/O and compuation simultaneously, it's time to consider moving your system calls to threads.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    thread = Thread(target=slow_systemcall)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "def compute_helicopter_location(index):\n",
    "    pass\n",
    "\n",
    "for i in range(5):\n",
    "    compute_helicopter_location(i)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Took {delta:.3f} seconds')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python threds can't run in parallel on multiple CPU cores because of the global interpreter lock (GIL).  \n",
    "\n",
    "Python threads are still useful despite the GIL because they provide an easy way to do multiple things seemingly at the same time.  \n",
    "\n",
    "Use Python threads to make multiple system calls in parallel.  This allows you to do blocking I/O at the same time as computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 54: Use `Lock` to Prevent Data Races in Threads\n",
    "\n",
    "The global interpreter lock will not protect you from data races in threads.  Although only one Python thread runs at a time, **a thread's operations on data structures can be interrupted between any two bytecode instructions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter should be 500000, got 444585\n"
     ]
    }
   ],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def increment(self, offset):\n",
    "        self.count += offset\n",
    "\n",
    "def worker(sensor_index, how_many, counter):\n",
    "    # I have a barrier in here so the workers synchronize\n",
    "    # when they start counting, otherwise it's hard to get a race\n",
    "    # because the overhead of starting a thread is high.\n",
    "    BARRIER.wait()\n",
    "    for _ in range(how_many):\n",
    "        # Read from the sensor\n",
    "        # Nothing actually happens here, but this is where\n",
    "        # the blocking I/O would go.\n",
    "        counter.increment(1)\n",
    "\n",
    "from threading import Barrier\n",
    "BARRIER = Barrier(5)\n",
    "from threading import Thread\n",
    "\n",
    "how_many = 10**5\n",
    "counter = Counter()\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    thread = Thread(target=worker,\n",
    "                    args=(i, how_many, counter))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "expected = how_many * 5\n",
    "found = counter.count\n",
    "print(f'Counter should be {expected}, got {found}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent data races and other forms of data structure corruption, Python includes a robust set of tools in the `threading` built-in module.  The simplest and most useful of them is the `Lock` class, which is a mutual-exclusion lock (mutex).  \n",
    "\n",
    "By using a lock, I can have the `Counter` class protect its current value against simultaneous accesses from multiple threads.  Even better is using it with the **context manager** `with` to act like a C++ lock guard that will then free the lock after the operation is complete, and prevent you from worrying about dead locks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter should be 500000, got 500000\n"
     ]
    }
   ],
   "source": [
    "from threading import Lock\n",
    "\n",
    "class LockingCounter:\n",
    "    def __init__(self):\n",
    "        self.lock = Lock()\n",
    "        self.count = 0\n",
    "\n",
    "    def increment(self, offset):\n",
    "        with self.lock:\n",
    "            self.count += offset\n",
    "\n",
    "BARRIER = Barrier(5)\n",
    "counter = LockingCounter()\n",
    "\n",
    "for i in range(5):\n",
    "    thread = Thread(target=worker,\n",
    "                    args=(i, how_many, counter))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "expected = how_many * 5\n",
    "found = counter.count\n",
    "print(f'Counter should be {expected}, got {found}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though Python has the GIL, you're still responsible for protecting against data races between the threads in your program.  \n",
    "\n",
    "Your programs will corrupt their data structures if you allow multiple threads to modify the same objects without mutexes.  \n",
    "\n",
    "Use the `Lock` class from the `threading` built-in module to enforce your program's invariants between multiple threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 55:  Use `Queue` to Coordinate Work Between Threads\n",
    "\n",
    "Python programs that do many things concurrently often need to coordinate their work.  One of the most useful arrangements for concurrent work is a pipeline of functions.  \n",
    "\n",
    "The handing off of work between pipeline phases can be modeled as a thread-safe **producer-consumer queue.**\n",
    "\n",
    "For example, say that I want to build a system that will take a constant stream of images from a digital camera, resize them, and then add them to a photo gallery online.  Such a program could be split into three phases of a pipeline.  New images are retrieved in the first phase, The downloaded images are passed through the resize function in the second phase.  The resized images are then consumed by the upload function in the final phase.\n",
    "\n",
    "### Let's take a look at a naive way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 items after polling 3033 times\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from threading import Lock\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def download(item):\n",
    "    return item\n",
    "\n",
    "def resize(item):\n",
    "    return item\n",
    "\n",
    "def upload(item):\n",
    "    return item\n",
    "\n",
    "class MyQueue:\n",
    "    def __init__(self):\n",
    "        self.items = deque()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def put(self, item):\n",
    "        with self.lock:\n",
    "            self.items.append(item)\n",
    "\n",
    "    def get(self):\n",
    "        with self.lock:\n",
    "            return self.items.popleft()\n",
    "\n",
    "\n",
    "class Worker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        self.polled_count = 0\n",
    "        self.work_done = 0\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            self.polled_count += 1\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                time.sleep(0.01)  # No work to do\n",
    "            except AttributeError:\n",
    "                # The magic exit signal\n",
    "                return\n",
    "            else:\n",
    "                result = self.func(item)\n",
    "                self.out_queue.put(result)\n",
    "                self.work_done += 1\n",
    "\n",
    "\n",
    "download_queue = MyQueue()\n",
    "resize_queue = MyQueue()\n",
    "upload_queue = MyQueue()\n",
    "done_queue = MyQueue()\n",
    "threads = [\n",
    "    Worker(download, download_queue, resize_queue),\n",
    "    Worker(resize, resize_queue, upload_queue),\n",
    "    Worker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "\n",
    "while len(done_queue.items) < 1000:\n",
    "    # Do something useful while waiting\n",
    "    time.sleep(0.1)\n",
    "# Stop all the threads by causing an exception in their\n",
    "# run methods.\n",
    "for thread in threads:\n",
    "    thread.in_queue = None\n",
    "    thread.join()\n",
    "    \n",
    "processed = len(done_queue.items)\n",
    "polled = sum(t.polled_count for t in threads)\n",
    "print(f'Processed {processed} items after '\n",
    "      f'polling {polled} times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the worker functions vary in their respective speeds, an earlier phase can prevent progress in later phases, backing up the pipeline.  This causes later phases to starve and constantly check their input queues for new work in a tight loop.  The outcome is that worker threads waste CPU time doing nothing useful: they're constantly raising and catching `IndexError` exceptions.\n",
    "\n",
    "The `Queue` class from the `queue` built-in module provides all of the functionality you need to solve the above problem and more.  `Queue` eliminates the busy waiting in the worker by making the `get` method block until new data is available.\n",
    "\n",
    "### Let's take a look at the better way to implement a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer waiting\n",
      "Producer putting\n",
      "Producer done\n",
      "Consumer done\n",
      "Producer put 1\n",
      "Consumer got 1\n",
      "Producer put 2\n",
      "Producer done\n",
      "Consumer got 2\n",
      "Consumer done\n",
      "Consumer waitingProducer putting\n",
      "Producer waiting\n",
      "\n",
      "Consumer working\n",
      "Consumer done\n",
      "Producer done\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "my_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    my_queue.get()              # Runs after put() below\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Example 12\n",
    "print('Producer putting')\n",
    "my_queue.put(object())          # Runs before get() above\n",
    "print('Producer done')\n",
    "thread.join()\n",
    "\n",
    "\n",
    "# Example 13\n",
    "my_queue = Queue(1)             # Buffer size of 1\n",
    "\n",
    "def consumer():\n",
    "    time.sleep(0.1)             # Wait\n",
    "    my_queue.get()              # Runs second\n",
    "    print('Consumer got 1')\n",
    "    my_queue.get()              # Runs fourth\n",
    "    print('Consumer got 2')\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Example 14\n",
    "my_queue.put(object())          # Runs first\n",
    "print('Producer put 1')\n",
    "my_queue.put(object())          # Runs third\n",
    "print('Producer put 2')\n",
    "print('Producer done')\n",
    "thread.join()\n",
    "\n",
    "\n",
    "# Example 15\n",
    "in_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    work = in_queue.get()       # Done second\n",
    "    print('Consumer working')\n",
    "    # Doing work\n",
    "    print('Consumer done')\n",
    "    in_queue.task_done()        # Done third\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "\n",
    "# Example 16\n",
    "print('Producer putting')\n",
    "in_queue.put(object())         # Done first\n",
    "print('Producer waiting')\n",
    "in_queue.join()                # Done fourth\n",
    "print('Producer done')\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Queue` class can also track the progress of work using the `task_done` method.  This lets you wait for a phase's intput `queue` to drain and eliminates the need to poll the last phase of a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 items finished\n"
     ]
    }
   ],
   "source": [
    "# Example 17\n",
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "\n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return  # Cause the thread to exit\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "\n",
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "\n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "threads = [\n",
    "    StoppableWorker(download, download_queue, resize_queue),\n",
    "    StoppableWorker(resize, resize_queue, upload_queue),\n",
    "    StoppableWorker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "\n",
    "download_queue.close()\n",
    "\n",
    "\n",
    "download_queue.join()\n",
    "resize_queue.close()\n",
    "resize_queue.join()\n",
    "upload_queue.close()\n",
    "upload_queue.join()\n",
    "print(done_queue.qsize(), 'items finished')\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach can be extended to using multiple worker threads per phase, which can increase I/O parallelism and speed up this type of program significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 items finished\n"
     ]
    }
   ],
   "source": [
    "def start_threads(count, *args):\n",
    "    threads = [StoppableWorker(*args) for _ in range(count)]\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    return threads\n",
    "\n",
    "def stop_threads(closable_queue, threads):\n",
    "    for _ in threads:\n",
    "        closable_queue.close()\n",
    "\n",
    "    closable_queue.join()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "\n",
    "download_threads = start_threads(\n",
    "    3, download, download_queue, resize_queue)\n",
    "resize_threads = start_threads(\n",
    "    4, resize, resize_queue, upload_queue)\n",
    "upload_threads = start_threads(\n",
    "    5, upload, upload_queue, done_queue)\n",
    "\n",
    "for _ in range(1000):\n",
    "    download_queue.put(object())\n",
    "\n",
    "stop_threads(download_queue, download_threads)\n",
    "stop_threads(resize_queue, resize_threads)\n",
    "stop_threads(upload_queue, upload_threads)\n",
    "\n",
    "print(done_queue.qsize(), 'items finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are a great way to organize sequences of work - especially I/O bound programs - that run concurrently using multiple Python threads.  \n",
    "\n",
    "Be aware of the many problems in biulding concurrent pipelines: busy waiting, how to tell workers to stop, and potential memory explosion.  \n",
    "The `Queue` class has all of the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 56: Know How to Recognize When Concurrency is Necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common types of concurrency coordination are **fan-out** (generating new units of concurrency), and **fan-in** (waiting for existing units of concurrency to complete).  Let's look at how this can be used to perform I/O while also running *The Game of Life*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---*-----\n",
      "----*----\n",
      "--***----\n",
      "---------\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from threading import Lock\n",
    "\n",
    "ALIVE = '*'\n",
    "EMPTY = '-'\n",
    "\n",
    "class Grid:\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.rows = []\n",
    "        for _ in range(self.height):\n",
    "            self.rows.append([EMPTY] * self.width)\n",
    "\n",
    "    def get(self, y, x):\n",
    "        return self.rows[y % self.height][x % self.width]\n",
    "\n",
    "    def set(self, y, x, state):\n",
    "        self.rows[y % self.height][x % self.width] = state\n",
    "\n",
    "    def __str__(self):\n",
    "        output = ''\n",
    "        for row in self.rows:\n",
    "            for cell in row:\n",
    "                output += cell\n",
    "            output += '\\n'\n",
    "        return output\n",
    "\n",
    "\n",
    "# Example 3\n",
    "grid = Grid(5, 9)\n",
    "grid.set(0, 3, ALIVE)\n",
    "grid.set(1, 4, ALIVE)\n",
    "grid.set(2, 2, ALIVE)\n",
    "grid.set(2, 3, ALIVE)\n",
    "grid.set(2, 4, ALIVE)\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need a way to set the status of neighboring cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neighbors(y, x, get):\n",
    "    n_ = get(y - 1, x + 0)  # North\n",
    "    ne = get(y - 1, x + 1)  # Northeast\n",
    "    e_ = get(y + 0, x + 1)  # East\n",
    "    se = get(y + 1, x + 1)  # Southeast\n",
    "    s_ = get(y + 1, x + 0)  # South\n",
    "    sw = get(y + 1, x - 1)  # Southwest\n",
    "    w_ = get(y + 0, x - 1)  # West\n",
    "    nw = get(y - 1, x - 1)  # Northwest\n",
    "    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]\n",
    "    count = 0\n",
    "    for state in neighbor_states:\n",
    "        if state == ALIVE:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the logic for the game based on the game's three rules:\n",
    "1. Die if a cell has fewer than two neighbors.\n",
    "2. Die if a cell has more than three neighbors.\n",
    "3. Become alive if an empty cell has exactly three neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     |     1     |     2     |     3     |     4    \n",
      "---*----- | --------- | --------- | --------- | ---------\n",
      "----*---- | --*-*---- | ----*---- | ---*----- | ----*----\n",
      "--***---- | ---**---- | --*-*---- | ----**--- | -----*---\n",
      "--------- | ---*----- | ---**---- | ---**---- | ---***---\n",
      "--------- | --------- | --------- | --------- | ---------\n"
     ]
    }
   ],
   "source": [
    "def game_logic(state, neighbors):\n",
    "    if state == ALIVE:\n",
    "        if neighbors < 2:\n",
    "            return EMPTY     # Die: Too few\n",
    "        elif neighbors > 3:\n",
    "            return EMPTY     # Die: Too many\n",
    "    else:\n",
    "        if neighbors == 3:\n",
    "            return ALIVE     # Regenerate\n",
    "    return state\n",
    "\n",
    "def step_cell(y, x, get, set):\n",
    "    state = get(y, x)\n",
    "    neighbors = count_neighbors(y, x, get)\n",
    "    next_state = game_logic(state, neighbors)\n",
    "    set(y, x, next_state)\n",
    "    \n",
    "def simulate(grid):\n",
    "    next_grid = Grid(grid.height, grid.width)\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            step_cell(y, x, grid.get, next_grid.set)\n",
    "    return next_grid\n",
    "\n",
    "class ColumnPrinter:\n",
    "    def __init__(self):\n",
    "        self.columns = []\n",
    "\n",
    "    def append(self, data):\n",
    "        self.columns.append(data)\n",
    "\n",
    "    def __str__(self):\n",
    "        row_count = 1\n",
    "        for data in self.columns:\n",
    "            row_count = max(\n",
    "                row_count, len(data.splitlines()) + 1)\n",
    "\n",
    "        rows = [''] * row_count\n",
    "        for j in range(row_count):\n",
    "            for i, data in enumerate(self.columns):\n",
    "                line = data.splitlines()[max(0, j - 1)]\n",
    "                if j == 0:\n",
    "                    padding = ' ' * (len(line) // 2)\n",
    "                    rows[j] += padding + str(i) + padding\n",
    "                else:\n",
    "                    rows[j] += line\n",
    "\n",
    "                if (i + 1) < len(self.columns):\n",
    "                    rows[j] += ' | '\n",
    "\n",
    "        return '\\n'.join(rows)\n",
    "    \n",
    "columns = ColumnPrinter()\n",
    "for i in range(5):\n",
    "    columns.append(str(grid))\n",
    "    grid = simulate(grid)\n",
    "    \n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works great for a program that can run in one thread on a single machine, but let's imagine that the program's requirements have changed and now I need to do some I/O from within the `game_logic` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_logic(state, neighbors):\n",
    "    # Do some blocking input/output in here:\n",
    "    data = my_socket.recv(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 57: Avoid Creating New `Thread` Instances for On-demand Fan-out\n",
    "\n",
    "Threads are the natural first tool to reach for in order to do parallel I/O in Python.  However, they have significant downsides when yo utry to use them for fanning out to many concurrent lines of execution.  Let's continue with the game of life example from above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "\n",
    "ALIVE = '*'\n",
    "EMPTY = '-'\n",
    "\n",
    "class Grid:\n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.rows = []\n",
    "        for _ in range(self.height):\n",
    "            self.rows.append([EMPTY] * self.width)\n",
    "\n",
    "    def get(self, y, x):\n",
    "        return self.rows[y % self.height][x % self.width]\n",
    "\n",
    "    def set(self, y, x, state):\n",
    "        self.rows[y % self.height][x % self.width] = state\n",
    "\n",
    "    def __str__(self):\n",
    "        output = ''\n",
    "        for row in self.rows:\n",
    "            for cell in row:\n",
    "                output += cell\n",
    "            output += '\\n'\n",
    "        return output\n",
    "\n",
    "class LockingGrid(Grid):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__(height, width)\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def __str__(self):\n",
    "        with self.lock:\n",
    "            return super().__str__()\n",
    "\n",
    "    def get(self, y, x):\n",
    "        with self.lock:\n",
    "            return super().get(y, x)\n",
    "\n",
    "    def set(self, y, x, state):\n",
    "        with self.lock:\n",
    "            return super().set(y, x, state)\n",
    "        \n",
    "def count_neighbors(y, x, get):\n",
    "    n_ = get(y - 1, x + 0)  # North\n",
    "    ne = get(y - 1, x + 1)  # Northeast\n",
    "    e_ = get(y + 0, x + 1)  # East\n",
    "    se = get(y + 1, x + 1)  # Southeast\n",
    "    s_ = get(y + 1, x + 0)  # South\n",
    "    sw = get(y + 1, x - 1)  # Southwest\n",
    "    w_ = get(y + 0, x - 1)  # West\n",
    "    nw = get(y - 1, x - 1)  # Northwest\n",
    "    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]\n",
    "    count = 0\n",
    "    for state in neighbor_states:\n",
    "        if state == ALIVE:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def game_logic(state, neighbors):\n",
    "    # Do some blocking input/output in here:\n",
    "    data = my_socket.recv(100)\n",
    "\n",
    "def game_logic(state, neighbors):\n",
    "    if state == ALIVE:\n",
    "        if neighbors < 2:\n",
    "            return EMPTY     # Die: Too few\n",
    "        elif neighbors > 3:\n",
    "            return EMPTY     # Die: Too many\n",
    "    else:\n",
    "        if neighbors == 3:\n",
    "            return ALIVE     # Regenerate\n",
    "    return state\n",
    "\n",
    "def step_cell(y, x, get, set):\n",
    "    state = get(y, x)\n",
    "    neighbors = count_neighbors(y, x, get)\n",
    "    next_state = game_logic(state, neighbors)\n",
    "    set(y, x, next_state)\n",
    "\n",
    "def simulate_threaded(grid):\n",
    "    next_grid = LockingGrid(grid.height, grid.width)\n",
    "\n",
    "    threads = []\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            args = (y, x, grid.get, next_grid.set)\n",
    "            thread = Thread(target=step_cell, args=args)\n",
    "            thread.start()  # Fan out\n",
    "            threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()       # Fan in\n",
    "\n",
    "    return next_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     |     1     |     2     |     3     |     4    \n",
      "---*----- | --------- | --------- | --------- | ---------\n",
      "----*---- | --*-*---- | ----*---- | ---*----- | ----*----\n",
      "--***---- | ---**---- | --*-*---- | ----**--- | -----*---\n",
      "--------- | ---*----- | ---**---- | ---**---- | ---***---\n",
      "--------- | --------- | --------- | --------- | ---------\n"
     ]
    }
   ],
   "source": [
    "class ColumnPrinter:\n",
    "    def __init__(self):\n",
    "        self.columns = []\n",
    "\n",
    "    def append(self, data):\n",
    "        self.columns.append(data)\n",
    "\n",
    "    def __str__(self):\n",
    "        row_count = 1\n",
    "        for data in self.columns:\n",
    "            row_count = max(\n",
    "                row_count, len(data.splitlines()) + 1)\n",
    "\n",
    "        rows = [''] * row_count\n",
    "        for j in range(row_count):\n",
    "            for i, data in enumerate(self.columns):\n",
    "                line = data.splitlines()[max(0, j - 1)]\n",
    "                if j == 0:\n",
    "                    padding = ' ' * (len(line) // 2)\n",
    "                    rows[j] += padding + str(i) + padding\n",
    "                else:\n",
    "                    rows[j] += line\n",
    "\n",
    "                if (i + 1) < len(self.columns):\n",
    "                    rows[j] += ' | '\n",
    "\n",
    "        return '\\n'.join(rows)\n",
    "\n",
    "grid = LockingGrid(5, 9)            # Changed\n",
    "grid.set(0, 3, ALIVE)\n",
    "grid.set(1, 4, ALIVE)\n",
    "grid.set(2, 2, ALIVE)\n",
    "grid.set(2, 3, ALIVE)\n",
    "grid.set(2, 4, ALIVE)\n",
    "\n",
    "columns = ColumnPrinter()\n",
    "for i in range(5):\n",
    "    columns.append(str(grid))\n",
    "    grid = simulate_threaded(grid)  # Changed\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works as expected, and the I/O is now parallelized between the threads.  However, this code has three big problems:\n",
    "1. The `Thread` instances require special tools to coorindate with each other safely.  This makes the code that uses threads harder to reason about than the procedural, single-threaded code from Item 56.  This complexity makes the threaded code more difficult to extend and maintain over time.  \n",
    "2. Threads require a lot of memory - about 8 MB per executing thread.  On many computers, that amount of memory doesn't matter for the 45 threads I'd need in this example, but if we decided to move to 100,000 cells, I would need to create a ton of threads, which would exhaust system memory.  Running a thread per concurrent activity just won't work.\n",
    "3. Starting a thread is costly, and threads have a negative performace impact when they run due to context switching between them.  In this case, all of the threads are started and stopped each generation of the game, which has high overhead and will increase latency beyond the expected I/O time of 100 milliseconds.\n",
    "\n",
    "This code would also be very difficult to debug if something went wrong.  For example, imagine that the `game_logic` function raises an exception, which is highly likely due to the generally flakey nature of I/O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_logic(state, neighbors):\n",
    "    raise OSError('Problem with I/O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can test what this would do by running a `Thread` instance pointed at this function and redirecting the sys.stderr output from the program to an in-memory `StringIO` buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-295:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-39-e22627dd5612>\", line 2, in game_logic\n",
      "OSError: Problem with I/O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "fake_stderr = io.StringIO()\n",
    "with contextlib.redirect_stderr(fake_stderr):\n",
    "    thread = Thread(target=game_logic, args=(ALIVE, 3))\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "\n",
    "print(fake_stderr.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `OSError` exception is raised as expected, but somehow the code that created the `Thread` and called `join` on it is unaffected.  This is because the `Thread` class will independently catch any exceptions that are raised by the target function and then write their traceback to `sys.stderr`.  Such exceptions are never re-raised to the caller that started the thread in the first place.\n",
    "\n",
    "Given all of these issues it's clear that threads are not the solution if you need to constantly create and finish new concurrent functions.\n",
    "\n",
    "Threads have many downsides:  They're costly to start and run if you need a lot of then, they each require a significant amount of memory, and they require special tools like `Lock` instances for coordination.  \n",
    "Threads do not provide a built-in way to raise exceptions back in the code that started a thread or that is waiting for one to finish, which makes them difficult to debug.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 58: Understand How Using `Queue` for Concurrency Requires Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
