{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Robustness and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 65: Take Advantage of Each Block in `try/except/else/finally`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 66: Consider `contextlib` and `with` Statements for Reusable `try/finally` Behavior\n",
    "\n",
    "The `with` statement in Python is used to indicate when code is running in a special context.  For example, mutual-exclusion locks can be used in `with` statements to indicate that the indented code block runs only while the lock is held:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "\n",
    "lock = Lock()\n",
    "with lock:\n",
    "    # do something\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is the same as using a try/finally construction except it will automatically `release` the lock and ensure you don't have to worry about doing it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context manager passed to a `with` statement may also return an object.  This object is assigned to a local variable in the `as` part of a compound statement.\n",
    "\n",
    "To enable your own funcitons to supply values for `as` targets, all you need to do is `yield` a value from your context manager:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 67: Use `datetime` Instead of `time` for Local Clocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl;dr avoid using the `time` module for translating between different time zones.  \n",
    "\n",
    "Use the `datetime` built-in module along with the `pytz` community module to reliably convert between times in different time zones.  \n",
    "\n",
    "Always represent time in UTC and do conversions to local time as the very fina lstep before presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 68:  Make `pickle` Reliable with `copyreg`\n",
    "\n",
    "The `pickle` built-in module can serialize Python objects into a stream of bytes and deserialize bytes back into objects.  Pickled byte streams shouldn't be used to communicate between untrusted parties.  The purpose of `pickle` is to let you pass Python objects between programs that you control over binary channels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 69:  Use `decimal` When Precision Is Paramount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.364999999999999\n",
      "5.365\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "rate = 1.45\n",
    "seconds = 3*60 + 42\n",
    "cost = rate * seconds / 60\n",
    "print(cost)\n",
    "\n",
    "rate = Decimal('1.45')\n",
    "seconds = Decimal(3*60 + 42)\n",
    "cost = rate * seconds / Decimal(60)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 70:  Profile Before Optimizing\n",
    "\n",
    "Python provides a built-in *profiler* for determining which parts of a program are responsible for execution time.  This means that you can focus your optimization efforts on the biggest sources of trouble and ignore parts of the program that don't impact speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         20003 function calls in 0.818 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.818    0.818 <ipython-input-8-319857f273fc>:26(<lambda>)\n",
      "        1    0.001    0.001    0.818    0.818 <ipython-input-8-319857f273fc>:5(insertion_sort)\n",
      "    10000    0.809    0.000    0.817    0.000 <ipython-input-8-319857f273fc>:13(insert_value)\n",
      "     9987    0.008    0.000    0.008    0.000 {method 'insert' of 'list' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7fd0e588e400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "from sys import stdout as STDOUT\n",
    "\n",
    "def insertion_sort(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        insert_value(result, value)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example 2\n",
    "def insert_value(array, value):\n",
    "    for i, existing in enumerate(array):\n",
    "        if existing > value:\n",
    "            array.insert(i, value)\n",
    "            return\n",
    "    array.append(value)\n",
    "\n",
    "\n",
    "# Example 3\n",
    "from random import randint\n",
    "\n",
    "max_size = 10**4\n",
    "data = [randint(0, max_size) for _ in range(max_size)]\n",
    "test = lambda: insertion_sort(data)\n",
    "\n",
    "\n",
    "# Example 4\n",
    "from cProfile import Profile\n",
    "\n",
    "profiler = Profile()\n",
    "profiler.runcall(test)\n",
    "\n",
    "\n",
    "# Example 5\n",
    "from pstats import Stats\n",
    "\n",
    "stats = Stats(profiler)\n",
    "stats = Stats(profiler, stream=STDOUT)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the profiler statistics table above, I can see that the biggest use of CPU in my test is the cumulative time spent in the `insert_value` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 71: Prefer `deque` for Producer-Consumer Queues\n",
    "\n",
    "Many people use lists for queues, but the issue is that in order to remove an item from the left of the list requires shifting all other elements of the list.  Python provides the `deque` class from the `collections` built-in module to solve this problem.  `deque` is a *double-ended queue* implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 72: Consider Searching Sorted Sequences with `bisect`\n",
    "\n",
    "Searching sorted data contained in a `list` takes linear time using the `index` method or a `for` loop with simple comparisons.  \n",
    "\n",
    "The `bisect` built-in module's `bisect_left` function takes logarithmic time to search for values in sorted lists, which can be orders of magnitude faster than other approaches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 73:  Know how to use `heapq` for Priority Queues\n",
    "\n",
    "Often times, instead of needing a FIFO queue, you'll need a program to process items in order of relative importance instead.  To accomplish this, a **priority queue** is the right tool for the job.\n",
    "\n",
    "A **heap** is a data structure that allows for a `list` of items to be maintained where the computational complexity of adding a new item or removing the smallest item has logarithmic computational complexity.  \n",
    "\n",
    "The `heapq` module requires items in the priority queue to be comparable and ahve a natural sort order, which requires special methods like `__lt__` to be defined for classes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 74:  Consider `memoryview` and `bytearray` for Zero-Copy Interactions with `bytes`  \n",
    "\n",
    "Python's built-in `memoryview` type exposes CPython's high-performance **buffer protocol** to programs.  The buffer protocol is a low-level C API that allows the Python runtime and C extensions to access the underlying data buffers that are behind objects like `bytes` instances.  The best part about `memoryview` instances is that slicing them results in another `memoryview` instance without copying the underlying data.\n",
    "\n",
    "By enabling `zero-copy` operations, `memoryview` can provide enormous speedups for code that needs to quickly process large amounts of memory, such as numerical C extensions like `NumPy` and other I/O bound programs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<memory at 0x7fd0e5025880>\n",
      "Size: 7\n",
      "Data in view: b'haricut'\n",
      "Underlying data: b'shave and a haricut, two bits'\n"
     ]
    }
   ],
   "source": [
    "data = b'shave and a haricut, two bits'\n",
    "view = memoryview(data)\n",
    "chunk = view[12:19]\n",
    "print(chunk)\n",
    "print(f'Size: {chunk.nbytes}')\n",
    "print(f'Data in view: {chunk.tobytes()}')\n",
    "print(f'Underlying data: {chunk.obj}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
